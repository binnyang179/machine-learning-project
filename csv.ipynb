{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DweYe9FcbMK_"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "AVV2e0XKbJeX"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUtoed20cRJJ"
   },
   "source": [
    "# Load CSV with tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ap_W4aQcgNT"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/beta/tutorials/load_data/text\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/r2/tutorials/load_data/csv.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/r2/tutorials/load_data/csv.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/r2/tutorials/load_data/csv.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-3Xbt0FfGfs"
   },
   "source": [
    "This tutorial provides an example of how to load CSV data from a file into a `tf.data.Dataset`.\n",
    "\n",
    "The data used in this tutorial are taken from the Titanic passenger list. We'll try to predict the likelihood a passenger survived based on characteristics like age, gender, ticket class, and whether the person was traveling alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgZ9gjmPfSnK"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:30:11.018064Z",
     "start_time": "2019-07-01T02:30:09.024891Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "baYFZMW_bJHh"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:30:24.426911Z",
     "start_time": "2019-07-01T02:30:24.423696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:54:37.636928Z",
     "start_time": "2019-07-01T02:54:37.391028Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Ncf5t6tgL5ZI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from file:///home/crab179/PycharmProjects/machine-learning-project/data/UAI_Data/train_July.csv\n",
      "180609024/180604886 [==============================] - 0s 0us/step\n",
      "Downloading data from file:///home/crab179/PycharmProjects/machine-learning-project/data/UAI_Data/test_Aug.csv\n",
      "19357696/19356800 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_URL = \"file:///home/crab179/PycharmProjects/machine-learning-project/data/UAI_Data/train_July.csv\"\n",
    "TEST_DATA_URL = \"file:///home/crab179/PycharmProjects/machine-learning-project/data/UAI_Data/test_Aug.csv\"\n",
    "\n",
    "train_file_path = tf.keras.utils.get_file(\"train_July.csv\", TRAIN_DATA_URL)\n",
    "test_file_path = tf.keras.utils.get_file(\"test_Aug.csv\", TEST_DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:54:50.020533Z",
     "start_time": "2019-07-01T02:54:50.018136Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4ONE94qulk6S"
   },
   "outputs": [],
   "source": [
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wuqj601Qw0Ml"
   },
   "source": [
    "## Load data\n",
    "\n",
    "So we know what we're doing, lets look at the top of the CSV file we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:55:36.189624Z",
     "start_time": "2019-07-01T02:55:36.068738Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "54Dv7mCrf9Yw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,driver_id,member_id,create_date,create_hour,status,estimate_money,estimate_distance,estimate_term,start_geo_id,end_geo_id\r",
      "\r\n",
      "583411b46a31bcc5d12d4402c928a146,3e69e17a6e5a726fe44d71896bee4f32,6b4d6e4992191fe96b9f27921520d551,2017-07-01,00,2,140.00,20099.00,18.00,6d7827e8dcfa09497954a31e6f7e6ee6,85e49ded1fa70a7bfa01ab0212a6e538\r",
      "\r\n",
      "396b6e317f915352d3a19f61d2657c46,034f5860624827a65191a9be919fbb3d,c7c93facfd1b10d4e75ff14f479484e2,2017-07-01,00,2,78.00,9000.00,18.00,27d75f17e61587172fe7a6827bbaa198,f5dc996f6aa097f7a84a9bcfe58ed55c\r",
      "\r\n",
      "c0badb35d04b00b06c54a285abde6e1b,d41d8cd98f00b204e9800998ecf8427e,8325f79b82f697dcce557b4a08f2ae5d,2017-07-01,00,1,86.23,10323.00,20.00,f92dfcc31699ad56d967a57673b8fc65,8c269e40d177f46840aff30baeb25e29\r",
      "\r\n",
      "9c67ee57c2217c3b2211a66b120d77b2,e4c4e24edd254bb81fc6e3fe7a1a5dd4,bee163f2587d01a9fd9070be4c1e24fc,2017-07-01,00,1,81.88,14197.00,27.00,92e1e8020813ef939183e345626b442a,f80c4ceeb36264b42e34d6c4c2cb9b4c\r",
      "\r\n",
      "fbd6734ac4938fab06546db06de9b3a9,d41d8cd98f00b204e9800998ecf8427e,644f9f79d6a02a71f048562aad301642,2017-07-01,02,1,217.01,39150.00,40.00,ca902ab284d4bb9e8c2a0bb58d55cf7b,6da3e22032d543214b2893d1c9f2b9e1\r",
      "\r\n",
      "3d8ba2ec8206a30453b59c5b3bc662bf,603bdb4e43ec2571e8724ae0dd78434c,3d48932ab348010df2971f06a56718d6,2017-07-01,02,1,55.69,8360.00,16.00,27d75f17e61587172fe7a6827bbaa198,f5dc996f6aa097f7a84a9bcfe58ed55c\r",
      "\r\n",
      "9147658c0f9684b7855293c66c561767,6ab41a361b7a640051de548b64a80ba0,06135b922cdc6244a317b43d54a1dff6,2017-07-01,06,2,188.00,40184.00,47.00,02d7ff35bd718436df52bf7f9cf8b4ba,6d7827e8dcfa09497954a31e6f7e6ee6\r",
      "\r\n",
      "f74e5c9ce61a92433844191be462b88c,e0de06ab535fcb347f7d46dfc78d7c9e,2ed0dd2d9cbc63b2e5055b7f664af679,2017-07-01,08,2,56.00,10953.00,21.00,92e1e8020813ef939183e345626b442a,0a64b01e91cf367a9b016d4f6d42290f\r",
      "\r\n",
      "56247cb614da0355aaf2f77b4cef05e0,b96a0278d839409bd48b3266c894cf12,62179b474800b65dccfe1aa4e79a1b83,2017-07-01,09,2,25.00,2889.00,5.00,465d8354075be67947793d4c2d79bced,578920cbc2397ae136ea7fe04ecda1a6\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head {train_file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOYKQKmMj3D6"
   },
   "source": [
    "As you can see, the columns in the CSV are labeled. We need the list later on, so let's read it out of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:56:30.017515Z",
     "start_time": "2019-07-01T02:56:30.013844Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "v0sLG216MtwT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'driver_id', 'member_id', 'create_date', 'create_hour', 'status', 'estimate_money', 'estimate_distance', 'estimate_term', 'start_geo_id', 'end_geo_id']\n"
     ]
    }
   ],
   "source": [
    "# CSV columns in the input file.\n",
    "with open(train_file_path, 'r') as f:\n",
    "    names_row = f.readline()\n",
    "\n",
    "\n",
    "CSV_COLUMNS = names_row.rstrip('\\n').split(',')\n",
    "print(CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:56:27.636423Z",
     "start_time": "2019-07-01T02:56:27.633002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'driver_id', 'member_id', 'create_date', 'create_hour', 'status', 'estimate_money', 'estimate_distance', 'estimate_term', 'start_geo_id', 'end_geo_id']\n"
     ]
    }
   ],
   "source": [
    "# CSV columns in the input file.\n",
    "with open(test_file_path, 'r') as f:\n",
    "    names_row = f.readline()\n",
    "\n",
    "\n",
    "CSV_COLUMNS = names_row.rstrip('\\n').split(',')\n",
    "print(CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZS-bt1LvWn2x"
   },
   "source": [
    " The dataset constructor will pick these labels up automatically.\n",
    "\n",
    "If the file you are working with does not contain the column names in the first line, pass them in a list of strings to  the `column_names` argument in the `make_csv_dataset` function.\n",
    "\n",
    "```python\n",
    "\n",
    "CSV_COLUMNS = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
    "\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "     ...,\n",
    "     column_names=CSV_COLUMNS,\n",
    "     ...)\n",
    "  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZfhoX7bR9u4"
   },
   "source": [
    "This example is going to use all the available columns. If you need to omit some columns from the dataset, create a list of just the columns you plan to use, and pass it into the (optional) `select_columns` argument of the constructor.\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "drop_columns = ['fare', 'embark_town']\n",
    "columns_to_use = [col for col in CSV_COLUMNS if col not in drop_columns]\n",
    "\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "  ...,\n",
    "  select_columns = columns_to_use, \n",
    "  ...)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67mfwr4v-mN_"
   },
   "source": [
    "We also have to identify which column will serve as the labels for each example, and what those labels are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-01T02:57:28.799332Z",
     "start_time": "2019-07-01T02:57:28.786526Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "iXROZm5f3V4E"
   },
   "outputs": [],
   "source": [
    "LABELS = [0, 1]\n",
    "LABEL_COLUMN = 'survived'\n",
    "\n",
    "FEATURE_COLUMNS = [column for column in CSV_COLUMNS if column != LABEL_COLUMN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4N-plO4tDXd"
   },
   "source": [
    "Now that these constructor argument values are in place,  read the CSV data from the file and create a dataset. \n",
    "\n",
    "(For the full documentation, see `tf.data.experimental.make_csv_dataset`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Co7UJ7gpNADC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0628 04:41:16.166034 140680645007104 deprecation.py:323] From /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/data/experimental/ops/readers.py:498: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n"
     ]
    }
   ],
   "source": [
    "def get_dataset(file_path):\n",
    "  dataset = tf.data.experimental.make_csv_dataset(\n",
    "      file_path,\n",
    "      batch_size=12, # Artificially small to make examples easier to show.\n",
    "      label_name=LABEL_COLUMN,\n",
    "      na_value=\"?\",\n",
    "      num_epochs=1,\n",
    "      ignore_errors=True)\n",
    "  return dataset\n",
    "\n",
    "raw_train_data = get_dataset(train_file_path)\n",
    "raw_test_data = get_dataset(test_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHUQFKoQI6G7"
   },
   "source": [
    "Each item in the dataset is a batch, represented as a tuple of (*many examples*, *many labels*). The data from the examples is organized in column-based tensors (rather than row-based tensors), each with as many elements as the batch size (12 in this case).\n",
    "\n",
    "It might help to see this yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qWtFYtwXIeuj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLES: \n",
      " OrderedDict([('sex', <tf.Tensor: id=170, shape=(12,), dtype=string, numpy=\n",
      "array([b'female', b'female', b'male', b'male', b'female', b'male',\n",
      "       b'female', b'male', b'male', b'female', b'female', b'male'],\n",
      "      dtype=object)>), ('age', <tf.Tensor: id=162, shape=(12,), dtype=float32, numpy=\n",
      "array([24., 22., 30., 28., 42., 28., 17., 32., 28., 24., 28.,  4.],\n",
      "      dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: id=168, shape=(12,), dtype=int32, numpy=array([0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 4], dtype=int32)>), ('parch', <tf.Tensor: id=169, shape=(12,), dtype=int32, numpy=array([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], dtype=int32)>), ('fare', <tf.Tensor: id=167, shape=(12,), dtype=float32, numpy=\n",
      "array([14.5  ,  7.75 , 16.1  , 82.171, 26.   ,  7.896, 12.   ,  7.896,\n",
      "        8.458, 13.   , 16.1  , 31.275], dtype=float32)>), ('class', <tf.Tensor: id=164, shape=(12,), dtype=string, numpy=\n",
      "array([b'Second', b'Third', b'Third', b'First', b'Second', b'Third',\n",
      "       b'Second', b'Third', b'Third', b'Second', b'Third', b'Third'],\n",
      "      dtype=object)>), ('deck', <tf.Tensor: id=165, shape=(12,), dtype=string, numpy=\n",
      "array([b'unknown', b'unknown', b'unknown', b'unknown', b'unknown',\n",
      "       b'unknown', b'unknown', b'unknown', b'unknown', b'unknown',\n",
      "       b'unknown', b'unknown'], dtype=object)>), ('embark_town', <tf.Tensor: id=166, shape=(12,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Southampton', b'Cherbourg',\n",
      "       b'Southampton', b'Southampton', b'Cherbourg', b'Southampton',\n",
      "       b'Queenstown', b'Southampton', b'Southampton', b'Southampton'],\n",
      "      dtype=object)>), ('alone', <tf.Tensor: id=163, shape=(12,), dtype=string, numpy=\n",
      "array([b'n', b'y', b'n', b'n', b'n', b'y', b'y', b'y', b'y', b'y', b'n',\n",
      "       b'n'], dtype=object)>)]) \n",
      "\n",
      "LABELS: \n",
      " tf.Tensor([1 1 0 0 1 0 1 0 0 0 1 0], shape=(12,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "examples, labels = next(iter(raw_train_data)) # Just the first batch.\n",
    "print(\"EXAMPLES: \\n\", examples, \"\\n\")\n",
    "print(\"LABELS: \\n\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cryz31lxs3e"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tSyrkSQwYHKi"
   },
   "source": [
    "### Categorical data\n",
    "\n",
    "Some of the columns in the CSV data are categorical columns. That is, the content should be one of a limited set of options.\n",
    "\n",
    "In the CSV, these options are represented as text. This text needs to be converted to numbers before the model can be trained. To facilitate that, we need to create a list of categorical columns, along with a list of the options available in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWDniduKMw-C"
   },
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "    'sex': ['male', 'female'],\n",
    "    'class' : ['First', 'Second', 'Third'],\n",
    "    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
    "    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
    "    'alone' : ['y', 'n']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Ii0YWsoKBVx"
   },
   "source": [
    "Write a function that takes a tensor of categorical values, matches it to a list of value names, and then performs a one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bP02_BflkDbv"
   },
   "outputs": [],
   "source": [
    "def process_categorical_data(data, categories):\n",
    "  \"\"\"Returns a one-hot encoded tensor representing categorical values.\"\"\"\n",
    "  \n",
    "  # Remove leading ' '.\n",
    "  data = tf.strings.regex_replace(data, '^ ', '')\n",
    "  # Remove trailing '.'.\n",
    "  data = tf.strings.regex_replace(data, r'\\.$', '')\n",
    "  \n",
    "  # ONE HOT ENCODE\n",
    "  # Reshape data from 1d (a list) to a 2d (a list of one-element lists)\n",
    "  data = tf.reshape(data, [-1, 1])\n",
    "  # For each element, create a new list of boolean values the length of categories,\n",
    "  # where the truth value is element == category label\n",
    "  data = tf.equal(categories, data)\n",
    "  # Cast booleans to floats.\n",
    "  data = tf.cast(data, tf.float32)\n",
    "  \n",
    "  # The entire encoding can fit on one line:\n",
    "  # data = tf.cast(tf.equal(categories, tf.reshape(data, [-1, 1])), tf.float32)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "To2qbBGGMO1D"
   },
   "source": [
    "To help you visualize this, we'll take a single category-column tensor from the first batch, preprocess it, and show the before and after state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ds7MOLMkK2Gf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=164, shape=(12,), dtype=string, numpy=\n",
       "array([b'Second', b'Third', b'Third', b'First', b'Second', b'Third',\n",
       "       b'Second', b'Third', b'Third', b'Second', b'Third', b'Third'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_tensor = examples['class']\n",
    "class_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HdDUSgpoTKfA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First', 'Second', 'Third']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_categories = CATEGORIES['class']\n",
    "class_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yHQeR47_ObpT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=189, shape=(12, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_class = process_categorical_data(class_tensor, class_categories)\n",
    "processed_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ACkc_cCaTuos"
   },
   "source": [
    "Notice the relationship between the lengths of the two inputs and the shape of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvvXM8m0T00O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of batch:  12\n",
      "Number of category labels:  3\n",
      "Shape of one-hot encoded tensor:  (12, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of batch: \", len(class_tensor.numpy()))\n",
    "print(\"Number of category labels: \", len(class_categories))\n",
    "print(\"Shape of one-hot encoded tensor: \", processed_class.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9AsbaFmCeJtF"
   },
   "source": [
    "### Continuous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2maE8d2ijsq"
   },
   "source": [
    "Continuous data needs to be normalized, so that the values fall between 0 and 1. To do that, write a function that multiplies each value by 1 over twice the mean of the column values.\n",
    "\n",
    "The function should also reshape the data into a two dimensional tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IwGOy61lkQw-"
   },
   "outputs": [],
   "source": [
    "def process_continuous_data(data, mean):\n",
    "  # Normalize data\n",
    "  data = tf.cast(data, tf.float32) * 1/(2*mean)\n",
    "  return tf.reshape(data, [-1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Yh8R7BujTAu"
   },
   "source": [
    "To do this calculation, you need the column means. You would obviously need to compute these in real life, but for this example we'll just provide them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iNE_mTJqegGQ"
   },
   "outputs": [],
   "source": [
    "MEANS = {\n",
    "    'age' : 29.631308,\n",
    "    'n_siblings_spouses' : 0.545455,\n",
    "    'parch' : 0.379585,\n",
    "    'fare' : 34.385399\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "raZtRlmaj-A5"
   },
   "source": [
    "Again, to see what this function is actually doing, we'll take a single tensor of continuous data and show it before and after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G-t_RSBrM2Vm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=162, shape=(12,), dtype=float32, numpy=\n",
       "array([24., 22., 30., 28., 42., 28., 17., 32., 28., 24., 28.,  4.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_tensor = examples['age']\n",
    "age_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9lMLaEsjq3K"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=198, shape=(12, 1), dtype=float32, numpy=\n",
       "array([[0.405],\n",
       "       [0.371],\n",
       "       [0.506],\n",
       "       [0.472],\n",
       "       [0.709],\n",
       "       [0.472],\n",
       "       [0.287],\n",
       "       [0.54 ],\n",
       "       [0.472],\n",
       "       [0.405],\n",
       "       [0.472],\n",
       "       [0.067]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_continuous_data(age_tensor, MEANS['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kPWkC4_1l3IG"
   },
   "source": [
    "### Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jIvyqVAXmsN4"
   },
   "source": [
    "Now assemble these preprocessing tasks into a single function that can be mapped to each batch in the dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rMxEHN0SNPkC"
   },
   "outputs": [],
   "source": [
    "def preprocess(features, labels):\n",
    "  \n",
    "  # Process categorial features.\n",
    "  for feature in CATEGORIES.keys():\n",
    "    features[feature] = process_categorical_data(features[feature],\n",
    "                                                 CATEGORIES[feature])\n",
    "\n",
    "  # Process continuous features.\n",
    "  for feature in MEANS.keys():\n",
    "    features[feature] = process_continuous_data(features[feature],\n",
    "                                                MEANS[feature])\n",
    "  \n",
    "  # Assemble features into a single tensor.\n",
    "  features = tf.concat([features[column] for column in FEATURE_COLUMNS], 1)\n",
    "  \n",
    "  return features, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "34K5ESbYnkg4"
   },
   "source": [
    "Now apply that function with `tf.Dataset.map`, and shuffle the dataset to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7M5km0f_1pVp"
   },
   "outputs": [],
   "source": [
    "train_data = raw_train_data.map(preprocess).shuffle(500)\n",
    "test_data = raw_test_data.map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQOWatzRr2aF"
   },
   "source": [
    "And let's see what a single example looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gc1o9ZpCsGGM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=365, shape=(12, 24), dtype=float32, numpy=\n",
       " array([[1.   , 0.   , 0.472, 0.   , 0.   , 0.115, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 1.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [0.   , 1.   , 0.472, 0.917, 0.   , 1.195, 1.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 1.   , 0.   , 0.   , 0.   , 1.   ],\n",
       "        [1.   , 0.   , 0.321, 0.   , 0.   , 0.153, 0.   , 1.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [0.   , 1.   , 0.607, 0.   , 2.634, 1.032, 1.   , 0.   , 0.   ,\n",
       "         0.   , 1.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n",
       "        [1.   , 0.   , 0.591, 0.   , 0.   , 0.386, 1.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 1.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.709, 0.917, 0.   , 0.756, 1.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n",
       "        [1.   , 0.   , 0.337, 0.   , 0.   , 0.134, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.607, 0.917, 0.   , 0.226, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n",
       "        [1.   , 0.   , 0.337, 0.   , 0.   , 0.143, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.658, 0.   , 0.   , 0.189, 0.   , 1.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.27 , 0.   , 0.   , 0.117, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.253, 0.917, 1.317, 0.105, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 1.   , 0.   , 0.   , 0.   , 1.   ]], dtype=float32)>,\n",
       " <tf.Tensor: id=366, shape=(12,), dtype=int32, numpy=array([0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0], dtype=int32)>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples, labels = next(iter(train_data))\n",
    "\n",
    "examples, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJnOromrse57"
   },
   "source": [
    "The examples are in a  two dimensional arrays of 12 items each (the batch size). Each item represents a single row in the original CSV file. The labels are a 1d tensor of 12 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlF_omQqtnOP"
   },
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQoFh16LxtT_"
   },
   "source": [
    "This example uses the [Keras Functional API](https://www.tensorflow.org/beta/guide/keras/functional) wrapped in a `get_model` constructor to build up a simple model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDM3FIgHNCW3"
   },
   "outputs": [],
   "source": [
    "def get_model(input_dim, hidden_units=[100]):\n",
    "  \"\"\"Create a Keras model with layers.\n",
    "\n",
    "  Args:\n",
    "    input_dim: (int) The shape of an item in a batch. \n",
    "    labels_dim: (int) The shape of a label.\n",
    "    hidden_units: [int] the layer sizes of the DNN (input layer first)\n",
    "    learning_rate: (float) the learning rate for the optimizer.\n",
    "\n",
    "  Returns:\n",
    "    A Keras model.\n",
    "  \"\"\"\n",
    "\n",
    "  inputs = tf.keras.Input(shape=(input_dim,))\n",
    "  x = inputs\n",
    "\n",
    "  for units in hidden_units:\n",
    "    x = tf.keras.layers.Dense(units, activation='relu')(x)\n",
    "  outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "  model = tf.keras.Model(inputs, outputs)\n",
    " \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ce9PRb_LzFpm"
   },
   "source": [
    "The `get_model` constructor needs to know the input shape of your data (not including the batch size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qX-DU34ZuKJX"
   },
   "outputs": [],
   "source": [
    "input_shape, output_shape = train_data.output_shapes\n",
    "\n",
    "input_dimension = input_shape.dims[1] # [0] is the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPdtI2ie0lEZ"
   },
   "source": [
    "## Train, evaluate, and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8gvw1RE9zXkD"
   },
   "source": [
    "Now the model can be instantiated and trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q_nm28IzNDTO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0628 04:41:17.067102 140680645007104 deprecation.py:323] From /tmpfs/src/tf_docs_env/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 17ms/step - loss: 0.6450 - accuracy: 0.6571\n",
      "Epoch 2/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7895\n",
      "Epoch 3/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.8134\n",
      "Epoch 4/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.8150\n",
      "Epoch 5/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8166\n",
      "Epoch 6/20\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.8182\n",
      "Epoch 7/20\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8214\n",
      "Epoch 8/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8246\n",
      "Epoch 9/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8230\n",
      "Epoch 10/20\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.8230\n",
      "Epoch 11/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8262\n",
      "Epoch 12/20\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8278\n",
      "Epoch 13/20\n",
      "53/53 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8262\n",
      "Epoch 14/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8278\n",
      "Epoch 15/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8325\n",
      "Epoch 16/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3945 - accuracy: 0.8341\n",
      "Epoch 17/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3926 - accuracy: 0.8357\n",
      "Epoch 18/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3905 - accuracy: 0.8357\n",
      "Epoch 19/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3886 - accuracy: 0.8373\n",
      "Epoch 20/20\n",
      "53/53 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff2682225c0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(input_dimension)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QyDMgBurzqQo"
   },
   "source": [
    "Once the model is trained, we can check its accuracy on the `test_data` set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eB3R3ViVONOp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22/Unknown - 0s 7ms/step - loss: 0.4435 - accuracy: 0.7879\n",
      "\n",
      "Test Loss 0.4434814710508693, Test Accuracy 0.7878788113594055\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "\n",
    "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTrn_pD90gdJ"
   },
   "source": [
    "Use `tf.keras.Model.predict` to infer labels on a batch or a dataset of batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qwcx74F3ojqe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted survival: 89.33%  | Actual outcome:  SURVIVED\n",
      "Predicted survival: 11.27%  | Actual outcome:  DIED\n",
      "Predicted survival: 41.55%  | Actual outcome:  SURVIVED\n",
      "Predicted survival: 80.50%  | Actual outcome:  DIED\n",
      "Predicted survival: 24.32%  | Actual outcome:  DIED\n",
      "Predicted survival: 98.60%  | Actual outcome:  SURVIVED\n",
      "Predicted survival: 8.59%  | Actual outcome:  DIED\n",
      "Predicted survival: 44.37%  | Actual outcome:  DIED\n",
      "Predicted survival: 93.19%  | Actual outcome:  SURVIVED\n",
      "Predicted survival: 11.09%  | Actual outcome:  DIED\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Show some results\n",
    "for prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\n",
    "  print(\"Predicted survival: {:.2%}\".format(prediction[0]),\n",
    "        \" | Actual outcome: \",\n",
    "        (\"SURVIVED\" if bool(survived) else \"DIED\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kMirhswgW_ln"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "tSyrkSQwYHKi",
    "9AsbaFmCeJtF",
    "kPWkC4_1l3IG"
   ],
   "name": "csv.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
